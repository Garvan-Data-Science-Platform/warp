
name: Test Illumina Genotyping Array

# Controls when the workflow will run
on:
  #run on push to feature branch "kp_GHA_Terra_auth_PD-2682" - REMOVE WHEN DONE TESTING
  push:
    branches:
      - kp_GHA_Terra_auth_PD-2682
  #pull_request:
  #  branches: [ "develop" ]
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    # inputs:
    #   image_tag:
    #     description: 'Docker Image Tag (default: branch_name)' 
env:
  PROJECT_NAME: WARP
  # Github repo name
  REPOSITORY_NAME: ${{ github.event.repository.name }}

jobs:
  run_pipeline:
    runs-on: ubuntu-latest
    # Add "id-token" with the intended permissions.
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    # actions/checkout MUST come before auth
    - uses: 'actions/checkout@v3'

    - id: 'auth'
      name: 'Authenticate to Google Cloud'
      uses: 'google-github-actions/auth@v2'
      with:
        token_format: 'access_token'
        # Centralized in dsp-tools-k8s; ask in #dsp-devops-champions for help troubleshooting
        workload_identity_provider: 'projects/1038484894585/locations/global/workloadIdentityPools/github-wi-pool/providers/github-wi-provider'
        # This is our tester service account
        service_account: 'pdt-tester@warp-pipeline-dev.iam.gserviceaccount.com'
        access_token_lifetime: '1000s' # optional, default: '3600s' (1 hour)
        access_token_scopes: 'profile, email, openid'

    # ... further steps are automatically authenticated
    - name: Check working directory
      run: |
        echo "Current directory:"
        pwd
        ls -lht
  
    - name: Submit job, poll status, and get outputs
      run: |
        # Set these environment variables or replace with your actual values
        TOKEN="${{ steps.auth.outputs.access_token }}"
        NAMESPACE="warp-pipelines"
        WORKSPACE="WARP Tests"
        
        # Function to call the Firecloud API using the firecloud_api.py script
        firecloud_action() {
            python3 scripts/firecloud_api/firecloud_api.py --token "$TOKEN" --namespace "$NAMESPACE" --workspace "$WORKSPACE" --action "$1" "${@:2}"
        }


        # Create the submission_data.json file
        SUBMISSION_DATA_FILE="submission_data.json"

        # Use a heredoc to generate the JSON file content dynamically
        cat <<EOF > "$SUBMISSION_DATA_FILE"
        {
          "methodConfigurationNamespace": "warp-pipelines",
          "methodConfigurationName": "IlluminaGenotypingArray",
          "useCallCache": true,
          "deleteIntermediateOutputFiles": true,
          "useReferenceDisks": true,
          "memoryRetryMultiplier": 1.2,
          "workflowFailureMode": "NoNewCalls",
          "userComment": "Automated submission",
          "ignoreEmptyOutputs": false
        }
        EOF

        echo "Created submission data file: $SUBMISSION_DATA_FILE"
        
        # 1. Submit a new workflow using the generated submission_data.json
        SUBMISSION_ID=$(firecloud_action submit --submission_data_file "$SUBMISSION_DATA_FILE")

        # Check if submission was successful
        if [ -z "$SUBMISSION_ID" ]; then
            echo "Submission failed."
            exit 1
        fi

        echo "Submission ID: $SUBMISSION_ID"

        # 2. Poll submission status and get workflow IDs and statuses
        RESPONSE=$(firecloud_action poll_status --submission_id "$SUBMISSION_ID")

        # Parse the JSON response to get the workflow ID and statuses
        echo "Workflows and their statuses:"
        echo "$RESPONSE" | jq

        # Check if RESPONSE is empty
        if [ -z "$RESPONSE" ]; then
            echo "Failed to retrieve Workflow IDs."
            exit 1
        fi

        # 3. Iterate over the Workflow IDs to get outputs
        PIPELINE_NAME="IlluminaGenotypingArray"

        for WORKFLOW_ID in $(echo "$RESPONSE" | jq -r 'keys[]'); do
            firecloud_action get_outputs --submission_id "$SUBMISSION_ID" --workflow_id "$WORKFLOW_ID" --pipeline_name "$PIPELINE_NAME"
        done
        echo "Workflow outputs retrieved successfully."

      
